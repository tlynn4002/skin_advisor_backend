from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional
from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM
from fastapi.middleware.cors import CORSMiddleware
from datasets import load_dataset

# ==== Load fine-tune dataset (ch·ªâ ƒë·ªÉ demo, kh√¥ng train online) ====
# File: skincare_asking.jsonl, m·ªói d√≤ng {"input": "...", "output": "..."}
dataset_file = "skincare_asking.jsonl"
dataset = load_dataset("json", data_files=dataset_file)["train"]

# ==== Load tokenizer & model Vit5 fine-tune n·∫øu c√≥ ====
# N·∫øu ch∆∞a fine-tune, d√πng model base
model_name = "./vit5-skinbot"  # ho·∫∑c "VietAI/vit5-base" n·∫øu ch∆∞a fine-tune
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

# ==== T·∫°o pipeline chatbot ====
chatbot = pipeline(
    "text2text-generation",
    model=model,
    tokenizer=tokenizer,
    device=0  # GPU Colab: 0, CPU: -1
)

# ==== Model ph√¢n lo·∫°i ·∫£nh da ====
image_model = pipeline("image-classification", model="microsoft/resnet-50")

# ==== FastAPI setup ====
app = FastAPI()
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ==== Request body ====
class RequestData(BaseModel):
    userMessage: str
    imageUrl: Optional[str] = None

SKIN_LABELS = {"face","skin","pimple","freckles","wrinkle","acne","blemish","complexion","nose","cheek","forehead"}

def filter_skin_labels(predictions):
    return ", ".join([r['label'] for r in predictions if r['label'].lower() in SKIN_LABELS])

# ==== Routes ====
@app.get("/")
async def root():
    return {"message": "Skin Advisor API (Colab Fine-Tune Vit5) is running üöÄ"}

@app.post("/skinAdvisor")
async def skin_advisor(data: RequestData):
    labels_text = ""
    if data.imageUrl and data.imageUrl.startswith(("http://","https://")):
        try:
            results = image_model(data.imageUrl)
            labels_text = filter_skin_labels(results)
        except:
            labels_text = ""

    # ==== Prompt c·ª±c an to√†n, friendly ====
    if labels_text:
        prompt = (
            f"B·∫°n l√† chuy√™n gia t∆∞ v·∫•n chƒÉm s√≥c da. "
            f"·∫¢nh da ng∆∞·ªùi d√πng cho th·∫•y: {labels_text}. "
            f"Ng∆∞·ªùi d√πng h·ªèi: {data.userMessage}. "
            "Tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán, b·∫±ng ti·∫øng Vi·ªát, ch·ªâ t∆∞ v·∫•n chƒÉm s√≥c da, tuy·ªát ƒë·ªëi kh√¥ng g·ª£i √Ω nguy hi·ªÉm."
        )
    else:
        prompt = (
            "B·∫°n l√† chuy√™n gia t∆∞ v·∫•n chƒÉm s√≥c da. "
            f"Ng∆∞·ªùi d√πng h·ªèi: {data.userMessage}. "
            "Tr·∫£ l·ªùi ng·∫Øn g·ªçn, th√¢n thi·ªán, b·∫±ng ti·∫øng Vi·ªát, ch·ªâ t∆∞ v·∫•n chƒÉm s√≥c da, tuy·ªát ƒë·ªëi kh√¥ng g·ª£i √Ω nguy hi·ªÉm."
        )

    try:
        result = chatbot(
            prompt,
            max_new_tokens=80
        )
        # Lo·∫°i b·ªè prompt g·ªëc n·∫øu model tr·∫£ v·ªÅ full text
        reply = result[0]["generated_text"].replace(prompt, "").strip()
    except:
        reply = "Xin l·ªói, bot ch∆∞a tr·∫£ l·ªùi ƒë∆∞·ª£c. Vui l√≤ng th·ª≠ l·∫°i."

    return {"reply": reply}